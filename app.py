# -*- coding: utf-8 -*-
import os
import fitz
import streamlit as st
import concurrent.futures
from docx import Document
from openai import OpenAI

# ========================
# é…ç½®åŒºåŸŸï¼ˆè¯·æ›¿æ¢APIå¯†é’¥ï¼‰âš ï¸
# ========================
DEEPSEEK_API_KEY = "sk-cba0efd438ce4ba8a548bbff7a9c80f1"
API_BASE_URL = "https://api.deepseek.com"

# ========================
# åˆå§‹åŒ–æœåŠ¡
# ========================
client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=API_BASE_URL)

# ========================
# è‡ªå®šä¹‰æ ·å¼
# ========================
def inject_custom_css():
    st.markdown("""
    <style>
    :root {
        --primary: #003366;
        --secondary: #E31837;
    }

    .header {
        background: linear-gradient(135deg, var(--primary), #004080);
        padding: 2rem;
        color: white;
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }

    .security-alert {
        background: #fff3cd;
        border-left: 5px solid #ffc107;
        padding: 1rem;
        margin: 1rem 0;
        border-radius: 4px;
    }

    .stDownloadButton>button {
        background-color: var(--primary) !important;
        color: white !important;
        border-radius: 20px;
    }

    .stProgress > div > div > div {
        background-color: var(--primary) !important;
    }
    </style>
    """, unsafe_allow_html=True)

# ========================
# æ ¸å¿ƒåŠŸèƒ½å‡½æ•°
# ========================
def extract_pdf_text(file):
    """æå–PDFæ–‡æœ¬å†…å®¹"""
    try:
        doc = fitz.open(stream=file.read(), filetype="pdf")
        return "\n".join(page.get_text("text") for page in doc)
    except Exception as e:
        st.error(f"PDFè§£æå¤±è´¥: {str(e)}")
        return ""

def generate_word_file(text, filename, action):
    """ç”ŸæˆWordæ–‡æ¡£"""
    try:
        doc = Document()
        doc.add_heading(f"{filename} - {action}", 0)
        doc.add_paragraph(text)
        output_path = f"{filename}_{action}.docx"
        doc.save(output_path)
        return output_path
    except Exception as e:
        st.error(f"ç”ŸæˆWordæ–‡ä»¶å¤±è´¥: {str(e)}")
        return None

def get_ai_response(prompt):
    """è·å–AIå›å¤"""
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{
                "role": "system",
                "content": "ä½ æ˜¯ä¸œå´è¯åˆ¸ä¸“ä¸šé‡‘èåˆ†æåŠ©æ‰‹ï¼Œæä¾›ä¸¥è°¨ä¸“ä¸šçš„åˆ†ææŠ¥å‘Š"
            }, {
                "role": "user", 
                "content": prompt
            }],
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"AIæœåŠ¡è¯·æ±‚å¤±è´¥: {str(e)}")
        return ""

# ========================
# ç•Œé¢æ¨¡å—
# ========================
def show_chat_interface():
    """èŠå¤©å¯¹è¯ç•Œé¢"""
    st.subheader("ğŸ’¬ æ™ºèƒ½é‡‘èé—®ç­”")
    
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    # æ˜¾ç¤ºèŠå¤©è®°å½•
    chat_container = st.container(height=500)
    with chat_container:
        for msg in st.session_state.chat_history:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])
    
    # è¾“å…¥å¤„ç†
    if prompt := st.chat_input("è¾“å…¥æ‚¨çš„é‡‘èé—®é¢˜..."):
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        
        with st.spinner("æ­£åœ¨ç”Ÿæˆä¸“ä¸šå›å¤..."):
            response = get_ai_response(prompt)
            st.session_state.chat_history.append({"role": "assistant", "content": response})
        
        st.rerun()

def show_document_interface():
    """æ–‡æ¡£å¤„ç†ç•Œé¢"""
    st.subheader("ğŸ“Š æ™ºèƒ½æ–‡æ¡£åˆ†æ")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ PDFæ–‡æ¡£ï¼ˆæ”¯æŒå¤šæ–‡ä»¶ï¼‰",
        type=["pdf"],
        accept_multiple_files=True,
        help="å•ä¸ªæ–‡ä»¶æœ€å¤§50MB"
    )
    
    if uploaded_files:
        # å¤„ç†é€‰é¡¹
        with st.expander("âš™ï¸ å¤„ç†è®¾ç½®", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                translate_on = st.checkbox("ç¿»è¯‘æ–‡æ¡£")
                lang = st.selectbox("ç›®æ ‡è¯­è¨€", ["è‹±è¯­", "æ—¥è¯­", "å¾·è¯­"], disabled=not translate_on)
                
                analysis_on = st.checkbox("ç”Ÿæˆä¸“ä¸šè§£è¯»")
                analysis_type = st.selectbox(
                    "è§£è¯»ç±»å‹",
                    ["è¡Œä¸šç ”ç©¶æŠ¥å‘Š", "å…¬å¸è´¢æŠ¥", "å¸‚åœºåˆ†æ"],
                    disabled=not analysis_on
                )
            
            with col2:
                summary_on = st.checkbox("ç”Ÿæˆæ‘˜è¦")
                detail_level = st.slider("æ‘˜è¦è¯¦ç»†ç¨‹åº¦", 1, 5, 3, disabled=not summary_on)
                
                if analysis_on:
                    risk_on = st.checkbox("åŒ…å«é£é™©è¯„ä¼°", value=True)
                    suggest_on = st.checkbox("åŒ…å«æŠ•èµ„å»ºè®®", value=True)

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹åˆ†æ", type="primary"):
            process_documents(
                uploaded_files,
                translate_on, 
                summary_on,
                analysis_on,
                {
                    "type": analysis_type,
                    "risk": risk_on,
                    "suggestion": suggest_on
                },
                detail_level
            )

def process_documents(files, translate_on, summary_on, analysis_on, analysis_params, detail_level):
    """å¤„ç†æ–‡æ¡£ä¸»å‡½æ•°"""
    with st.status("æ­£åœ¨åˆ†ææ–‡æ¡£...", expanded=True) as status:
        results = {}
        progress_bar = st.progress(0)
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            futures = []
            for file in files:
                futures.append(executor.submit(
                    process_single_document,
                    file, 
                    translate_on,
                    summary_on,
                    analysis_on,
                    analysis_params,
                    detail_level
                ))
            
            for i, future in enumerate(concurrent.futures.as_completed(futures)):
                try:
                    file_name, outputs = future.result()
                    results[file_name] = outputs
                    progress_bar.progress((i+1)/len(files))
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        
        status.update(label="åˆ†æå®Œæˆ", state="complete")
    
    # æ˜¾ç¤ºç»“æœ
    if results:
        st.subheader("ğŸ“ å¤„ç†ç»“æœ")
        for file_name, outputs in results.items():
            with st.expander(f"ğŸ“„ {file_name}", expanded=True):
                for action, path in outputs.items():
                    with open(path, "rb") as f:
                        st.download_button(
                            label=f"ä¸‹è½½ {action}",
                            data=f.read(),
                            file_name=os.path.basename(path),
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                        )

def process_single_document(file, translate_on, summary_on, analysis_on, analysis_params, detail_level):
    """å¤„ç†å•ä¸ªæ–‡æ¡£"""
    outputs = {}
    text = extract_pdf_text(file)
    
    if not text:
        return file.name, outputs
    
    # ç¿»è¯‘å¤„ç†
    if translate_on:
        prompt = f"å°†ä»¥ä¸‹å†…å®¹å‡†ç¡®ç¿»è¯‘ä¸ºè‹±æ–‡ï¼Œä¿ç•™ä¸“ä¸šæœ¯è¯­å’Œæ•°å­—ç²¾åº¦ï¼š\n\n{text[:15000]}"
        translated = get_ai_response(prompt)
        if translated:
            trans_path = generate_word_file(translated, file.name, "ç¿»è¯‘æ–‡æ¡£")
            if trans_path:
                outputs["ç¿»è¯‘æ–‡æ¡£"] = trans_path
    
    # æ‘˜è¦ç”Ÿæˆ
    if summary_on:
        prompt = f'''ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦ï¼ˆè¯¦ç»†ç¨‹åº¦{detail_level}/5ï¼‰ï¼š
        - ä½¿ç”¨åˆ†ç‚¹åˆ—è¡¨å‘ˆç°
        - å…³é”®æ•°æ®ç”¨ã€ã€‘æ ‡æ³¨
        - åŒ…å«æ ¸å¿ƒç»“è®ºå’Œé£é™©æç¤º
        æ–‡æ¡£å†…å®¹ï¼š{text[:15000]}'''
        summary = get_ai_response(prompt)
        if summary:
            summary_path = generate_word_file(summary, file.name, "å†…å®¹æ‘˜è¦")
            if summary_path:
                outputs["å†…å®¹æ‘˜è¦"] = summary_path
    
    # ç ”ç©¶æŠ¥å‘Šè§£è¯»
    if analysis_on and text:
        prompt = f'''
        ä½œä¸º{analysis_params['type']}åˆ†æå¸ˆï¼Œè¯·ä»ä»¥ä¸‹ç»´åº¦è§£è¯»æ–‡æ¡£ï¼š
        1. æ ¸å¿ƒè§‚ç‚¹æ€»ç»“ï¼ˆä¸è¶…è¿‡3æ¡ï¼‰
        2. å…³é”®æ•°æ®é€è§†ï¼ˆè¡¨æ ¼å‘ˆç°ï¼‰
        { "3. é£é™©è¯„ä¼°ï¼ˆâ˜…â˜…â˜…â˜†ï¼‰" if analysis_params['risk'] else ""}
        { "4. æŠ•èµ„å»ºè®®ï¼ˆæ˜ç¡®ä¹°å–è¯„çº§ï¼‰" if analysis_params['suggestion'] else ""}
        5. åç»­å…³æ³¨é‡ç‚¹
        
        æ–‡æ¡£åç§°ï¼šã€Š{file.name}ã€‹
        å†…å®¹ï¼š{text[:15000]}
        '''
        analysis = get_ai_response(prompt)
        if analysis:
            analysis_path = generate_word_file(analysis, file.name, "ä¸“ä¸šè§£è¯»")
            if analysis_path:
                outputs["ç ”ç©¶æŠ¥å‘Šè§£è¯»"] = analysis_path
    
    return file.name, outputs

# ========================
# ä¸»ç¨‹åº
# ========================
def main():
    st.set_page_config(
        page_title="ä¸œå´æ™ºç ”é‡‘èåŠ©æ‰‹",
        page_icon="ğŸ“ˆ",
        layout="wide"
    )
    inject_custom_css()
    
    # å®‰å…¨æç¤º
    st.markdown("""
    <div class="security-alert">
        âš ï¸ å®‰å…¨æç¤ºï¼šå½“å‰ä¸ºæœ¬åœ°æµ‹è¯•æ¨¡å¼ï¼Œè¯·å‹¿åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨æ­¤é…ç½®ï¼
    </div>
    """, unsafe_allow_html=True)
    
    # é¡µçœ‰
    st.markdown("""
    <div class="header">
        <h1>ä¸œå´æ™ºç ” AI å¹³å°</h1>
        <p>ä¸“ä¸šé‡‘èåˆ†æä¸æ–‡æ¡£å¤„ç†ç³»ç»Ÿ</p>
    </div>
    """, unsafe_allow_html=True)
    
    # å¯¼èˆªèœå•
    page = st.sidebar.radio(
        "åŠŸèƒ½å¯¼èˆª",
        ["ğŸ’¬ æ™ºèƒ½å¯¹è¯", "ğŸ“ æ–‡æ¡£åˆ†æ"],
        label_visibility="collapsed"
    )
    
    if page == "ğŸ’¬ æ™ºèƒ½å¯¹è¯":
        show_chat_interface()
    else:
        show_document_interface()

if __name__ == "__main__":
    main()
